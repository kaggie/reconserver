{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Relaying Jobs via `relay_server.py`\n",
    "\n",
    "This notebook demonstrates how to submit a job through the `relay_server.py` to a backend `server_app.py` (reconstruction server).\n",
    "\n",
    "**Functionality Demonstrated:**\n",
    "*   Client submits a job to the Relay Server.\n",
    "*   Relay Server receives the job and its files, stores files temporarily.\n",
    "*   Relay Server selects a Backend Server.\n",
    "*   Relay Server forwards the job and files to the Backend Server.\n",
    "*   Backend Server queues the job.\n",
    "*   Relay Server confirms to the Client that the job has been relayed and queued on a backend.\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  The core job forwarding logic (client -> relay -> backend queueing) must be implemented and working in `relay_server.py`.\n",
    "2.  Full result relaying (DICOMs and final status from backend -> relay -> client) might be a pending feature in `relay_server.py`. This notebook primarily focuses on the submission path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Instructions\n",
    "\n",
    "To run this notebook successfully, you need three components running, ideally in separate terminals:\n",
    "\n",
    "### 1.1. Backend Reconstruction Server (`server_app.py`)\n",
    "\n",
    "*   **Configuration (`recon.opts` for the backend server):**\n",
    "    *   Ensure `SERVER_PORT` is set (e.g., `SERVER_PORT = 60000`).\n",
    "    *   Set a unique `SHARED_KEY` (e.g., `SHARED_KEY = YourBackendServerKey`). This key will be used by the Relay to connect to this Backend.\n",
    "    *   Optionally, configure `SERVER_ADMIN_PORT` and `SERVER_ADMIN_SHARED_KEY` if you want to monitor it with `server_admin_cli.py`.\n",
    "    *   Make sure `RECON_SCRIPT_PATH` points to a valid (even if dummy) executable script. For this test, a simple script that creates a dummy output file in the job's output directory would suffice if you want to test end-to-end file creation.\n",
    "    ```\n",
    "    # Example recon.opts for backend server_app.py\n",
    "    SERVER_HOSTNAME = localhost\n",
    "    SERVER_PORT = 60000 \n",
    "    SHARED_KEY = YourBackendServerKey # IMPORTANT! Used by Relay to connect to this backend\n",
    "    LOG_FILEPATH = /tmp/backend_server.log\n",
    "    LOG_LEVEL = DEBUG \n",
    "    RECON_SERVER_BASE_PFILE_DIR = /tmp/backend_server_pfiles\n",
    "    RECON_JOB_OUTPUT_BASE_DIR = /tmp/backend_server_job_outputs\n",
    "    RECON_SCRIPT_PATH = ./default_recon_script.sh # Ensure this exists and is executable\n",
    "    MAX_CONCURRENT_JOBS = 1\n",
    "    SERVER_ADMIN_PORT = 60003\n",
    "    SERVER_ADMIN_SHARED_KEY = YourBackendAdminKey\n",
    "    MAX_CPU_LOAD_PERCENT = 90\n",
    "    MIN_AVAILABLE_MEMORY_MB = 100\n",
    "    ```\n",
    "*   **Command to Run:**\n",
    "    ```bash\n",
    "    python server_app.py --opts recon.opts # (ensure recon.opts is configured for backend)\n",
    "    ```\n",
    "\n",
    "### 1.2. Relay Server (`relay_server.py`)\n",
    "\n",
    "*   **Configuration (`relay.opts` for the relay server):**\n",
    "    *   `RELAY_PORT`: Port for clients (this notebook) to connect to (e.g., `RELAY_PORT = 60001`).\n",
    "    *   `SHARED_KEY_RELAY_TO_CLIENTS`: Shared key for clients connecting to the relay (e.g., `SHARED_KEY_RELAY_TO_CLIENTS = YourRelayToClientKey`).\n",
    "    *   `BACKEND_SERVERS`: List of backend server addresses. For this test, it should point to your running `server_app.py` instance (e.g., `BACKEND_SERVERS = localhost:60000`).\n",
    "    *   `SHARED_KEY_FOR_BACKENDS`: **Must match** the `SHARED_KEY` of the backend `server_app.py` (e.g., `SHARED_KEY_FOR_BACKENDS = YourBackendServerKey`).\n",
    "    *   `RELAY_JOB_TEMP_DIR`: Path for relay's temporary file storage (e.g., `/tmp/relay_job_files`).\n",
    "    *   Optionally, configure `RELAY_ADMIN_PORT` and `RELAY_ADMIN_SHARED_KEY` for `relay_server_cli.py`.\n",
    "    ```\n",
    "    # Example relay.opts\n",
    "    RELAY_HOSTNAME = localhost\n",
    "    RELAY_PORT = 60001\n",
    "    SHARED_KEY_RELAY_TO_CLIENTS = YourRelayToClientKey # For this notebook to connect to relay\n",
    "    LOG_FILEPATH = /tmp/relay_server.log\n",
    "    LOG_LEVEL = DEBUG\n",
    "    BACKEND_SERVERS = localhost:60000 # Points to server_app.py instance\n",
    "    SHARED_KEY_FOR_BACKENDS = YourBackendServerKey # MUST MATCH SHARED_KEY in backend's recon.opts\n",
    "    RELAY_JOB_TEMP_DIR = /tmp/relay_job_files\n",
    "    RELAY_ADMIN_PORT = 60002\n",
    "    RELAY_ADMIN_SHARED_KEY = YourRelayAdminKey\n",
    "    ```\n",
    "*   **Command to Run:**\n",
    "    ```bash\n",
    "    python relay_server.py --opts relay.opts\n",
    "    ```\n",
    "\n",
    "### 1.3. Client (This Notebook)\n",
    "\n",
    "*   This notebook will act as the client.\n",
    "*   We will create a temporary configuration file (`client_to_relay.opts`) for the `ReconClientApp` instance used by this notebook. This configuration will point to the **Relay Server's client-facing port** and use the **`SHARED_KEY_RELAY_TO_CLIENTS`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Dummy Input Files\n",
    "\n",
    "We'll create some dummy files for the job submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dummy_files_dir = \"dummy_input_files_for_relay_test\"\n",
    "os.makedirs(dummy_files_dir, exist_ok=True)\n",
    "\n",
    "dummy_file1_path = os.path.join(dummy_files_dir, \"P_dummy_relay1.7\")\n",
    "dummy_file2_path = os.path.join(dummy_files_dir, \"calibration_relay_dummy.dat\")\n",
    "\n",
    "with open(dummy_file1_path, 'w') as f:\n",
    "    f.write(\"This is a dummy PFILE for relay testing.\")\n",
    "\n",
    "with open(dummy_file2_path, 'w') as f:\n",
    "    f.write(\"This is a dummy calibration file for relay testing.\")\n",
    "\n",
    "print(f\"Created dummy file: {dummy_file1_path}\")\n",
    "print(f\"Created dummy file: {dummy_file2_path}\")\n",
    "\n",
    "recon_options_example = {\n",
    "    \"pyscript_name\": \"slicerecon_ relayed\",\n",
    "    \"num_slices\": 64,\n",
    "    \"relayed_job\": True\n",
    "}\n",
    "print(f\"Example recon options for relayed job: {json.dumps(recon_options_example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Client Configuration and Initialization\n",
    "\n",
    "We need to configure our `ReconClientApp` instance to talk to the **Relay Server**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "project_root = os.path.abspath(\"..\") # If notebook is in a subdir, adjust if needed\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "try:\n",
    "    from client_app import ReconClientApp\n",
    "    from reconlibs import readoptions # readoptions is used by client_app\n",
    "    print(\"Successfully imported ReconClientApp and readoptions.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}. Ensure this notebook is in the project root or adjust sys.path.\")\n",
    "    # You might need to restart the kernel after fixing the path.\n",
    "\n",
    "# Create a temporary opts file for this notebook's client instance\n",
    "client_opts_content = \"\"\"\n",
    "SERVER_HOSTNAME = localhost\n",
    "SERVER_PORT = 60001 # Relay's client-facing port\n",
    "SHARED_KEY = YourRelayToClientKey # Key for client to relay communication\n",
    "LOG_FILEPATH = /tmp/notebook_client_to_relay.log\n",
    "LOG_LEVEL = DEBUG\n",
    "CLIENT_DOWNLOAD_DIR = client_downloads_from_relay_test\n",
    "\"\"\"\n",
    "notebook_client_opts_file = \"temp_client_to_relay.opts\"\n",
    "with open(notebook_client_opts_file, 'w') as f:\n",
    "    f.write(client_opts_content)\n",
    "print(f\"Created temporary client opts file: {notebook_client_opts_file}\")\n",
    "\n",
    "# Initialize ReconClientApp\n",
    "relay_client = ReconClientApp(options_file=notebook_client_opts_file)\n",
    "print(\"ReconClientApp (to connect to Relay) initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submitting Job to Relay Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_submission_response = None\n",
    "\n",
    "if relay_client.connect():\n",
    "    print(\"Connected to Relay Server successfully.\")\n",
    "    \n",
    "    files_to_submit = [dummy_file1_path, dummy_file2_path]\n",
    "    \n",
    "    # The submit_recon_job method handles the interaction for submitting the job and its files\n",
    "    # and waits for the 'job_queued' (or in this case 'job_relayed_and_queued') response.\n",
    "    relayed_job_id = relay_client.submit_recon_job(\n",
    "        files_to_process=files_to_submit, \n",
    "        recon_options=recon_options_example\n",
    "    )\n",
    "    \n",
    "    if relayed_job_id:\n",
    "        print(f\"Job successfully submitted to Relay. Relay Job ID (from client perspective): {relayed_job_id}\")\n",
    "        # The actual response from relay_server's 'job_relayed_and_queued' might be more complex.\n",
    "        # We need to inspect what submit_recon_job actually returns in the context of a relay.\n",
    "        # For now, we assume `relayed_job_id` is the `job_id` from the *backend* if the relay passes it through,\n",
    "        # or the relay's own job ID.\n",
    "        # The `submit_recon_job` in `client_app` expects the `job_id` in the 'job_queued' payload.\n",
    "        # Relay server sends 'job_relayed_and_queued' with 'relay_job_id' and 'backend_job_id'.\n",
    "        # The client's submit_recon_job was designed for 'job_queued', so its direct return might be the 'job_id' field if present.\n",
    "        # We should check the actual last message or adapt client if needed.\n",
    "        \n",
    "        # Let's assume the `submit_recon_job` returns the primary job ID it cares about (which would be the backend one if the relay is transparent about it)\n",
    "        # or we can inspect the last message if the relay sends a custom response type.\n",
    "        last_message = relay_client.sf_client.last_received_message\n",
    "        if last_message and last_message.get(\"type\") == \"job_relayed_and_queued\":\n",
    "            print(\"Detailed response from Relay:\")\n",
    "            print(json.dumps(last_message.get(\"payload\"), indent=2))\n",
    "            job_submission_response = last_message.get(\"payload\")\n",
    "        else:\n",
    "            print(f\"Standard job_id from submit_recon_job: {relayed_job_id} (may or may not be backend_job_id depending on relay's response structure)\")\n",
    "            print(f\"Last raw message from server (relay): {last_message}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Job submission to Relay failed.\")\n",
    "    \n",
    "    # Note: The client's default `process_job_and_get_results` would expect DICOMs etc.\n",
    "    # from the direct server it connected to (the relay). This part of the relay is TBD.\n",
    "    \n",
    "    relay_client.disconnect()\n",
    "    print(\"Disconnected from Relay Server.\")\n",
    "else:\n",
    "    print(\"Failed to connect to the Relay Server. Ensure it's running and client_to_relay.opts is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monitoring the System (Using Admin CLIs)\n",
    "\n",
    "After submitting the job to the relay, you can use the provided CLI tools in separate terminals to monitor the components.\n",
    "\n",
    "**Assumptions for CLI commands:**\n",
    "*   You have `relay.opts` configured for the relay server (including its admin port/key).\n",
    "*   You have `recon.opts` configured for the backend `server_app.py` (including its admin port/key).\n",
    "\n",
    "### 4.1. Check Relay Server Status\n",
    "```bash\n",
    "# In a new terminal:\n",
    "python relay_server_cli.py status --opts relay.opts \n",
    "```\n",
    "*(Expected: Shows relay uptime, client connection count during submission, etc.)*\n",
    "\n",
    "### 4.2. Check Relay's Backend Health\n",
    "```bash\n",
    "# In a new terminal:\n",
    "python relay_server_cli.py backends --opts relay.opts\n",
    "```\n",
    "*(Expected: Shows the backend server (e.g., `localhost:60000`) and its health status as 'Yes' if the relay can connect to it.)*\n",
    "\n",
    "### 4.3. Check Backend Server's Job Queue\n",
    "```bash\n",
    "# In a new terminal, targeting the backend server's recon.opts:\n",
    "python server_admin_cli.py queue --opts recon.opts \n",
    "```\n",
    "*(Expected: You should see the job (identified by `backend_job_id` from the relay's response) listed in the backend server's queue.)*\n",
    "\n",
    "### 4.4. Check Backend Server's Worker Status\n",
    "```bash\n",
    "# In a new terminal, targeting the backend server's recon.opts:\n",
    "python server_admin_cli.py workers --opts recon.opts\n",
    "```\n",
    "*(Expected: If the job is simple/fast, it might already be processing or completed. You might see a worker busy with the `backend_job_id`.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Running CLI commands from Notebook (for quick check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_cli_command(command):\n",
    "    print(f\"\\nRunning: {command}\\n\")\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "        print(\"Output:\\n\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error Output:\\n\", e.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Command not found. Ensure the CLI script is in the path or project root.\")\n",
    "\n",
    "# Note: These commands assume relay.opts and recon.opts are in the same directory as the notebook.\n",
    "# You might need to adjust paths or run servers first.\n",
    "\n",
    "print(\"--- Checking Relay Status (relay.opts) ---\")\n",
    "run_cli_command(\"python relay_server_cli.py status --opts relay.opts\")\n",
    "\n",
    "print(\"\\n--- Checking Backend Health via Relay (relay.opts) ---\")\n",
    "run_cli_command(\"python relay_server_cli.py backends --opts relay.opts\")\n",
    "\n",
    "print(\"\\n--- Checking Backend Server Queue (recon.opts for backend) ---\")\n",
    "run_cli_command(\"python server_admin_cli.py queue --opts recon.opts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Result Handling\n",
    "\n",
    "The current implementation of `relay_server.py` focuses on forwarding the job submission to a backend server and confirming to the client that the job has been *queued* on the backend. \n",
    "\n",
    "**Key points regarding results:**\n",
    "*   **Job Queued Confirmation**: The notebook demonstrates receiving the `job_relayed_and_queued` message, which includes the `relay_job_id` (internal to relay operations) and the `backend_job_id` (the ID of the job on the actual reconstruction server).\n",
    "*   **Result File Relaying (TBD)**: The full relaying of result files (e.g., DICOMs) and final status messages (`recon_complete` or `job_failed`) from the backend server, through the relay, and back to the original client is a more complex part of the relay functionality and is **considered a pending feature for `relay_server.py`** as of this notebook's creation.\n",
    "*   **Client Behavior**: The `ReconClientApp`'s `submit_recon_job` method as used here is primarily for the submission phase. A more complete interaction involving result download would typically use `run_full_job_cycle` or a sequence including `process_job_and_get_results(job_id)`. However, these methods in the client would expect the *relay server* to behave like the *end server* regarding result delivery. This requires the relay to implement the result forwarding logic.\n",
    "\n",
    "To get actual results for a job submitted via the relay, you would currently need to interact directly with the backend server, potentially using its `CLIENT_DOWNLOAD_DIR` if you have access, or by implementing a client that connects directly to the backend server once you know the `backend_job_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleanup: Remember to stop the backend server_app.py and relay_server.py processes in their terminals.\")\n",
    "\n",
    "try:\n",
    "    if os.path.exists(notebook_client_opts_file):\n",
    "        os.remove(notebook_client_opts_file)\n",
    "        print(f\"Removed temporary client opts file: {notebook_client_opts_file}\")\n",
    "    \n",
    "    if os.path.exists(dummy_files_dir):\n",
    "        shutil.rmtree(dummy_files_dir)\n",
    "        print(f\"Removed dummy input files directory: {dummy_files_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during cleanup: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
